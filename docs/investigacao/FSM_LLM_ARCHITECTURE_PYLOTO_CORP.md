# ğŸ—ï¸ Arquitetura FSM + LLM Inteligente para pyloto_corp

**Objetivo:** Implementar sistema de estados (FSM) similar a `pyloto_lab`, com seleÃ§Ã£o inteligente de tipos de mensagens via LLM  
**Data:** 26 de janeiro de 2025  
**Status:** ğŸ“‹ Documento de Design e ImplementaÃ§Ã£o  
**Escopo:** pyloto_corp (serviÃ§o de atendimento inicial WhatsApp)

---

## ğŸ“‘ Ãndice

1. [AnÃ¡lise Comparativa](#1-anÃ¡lise-comparativa)
2. [PadrÃ£o FSM em pyloto_lab](#2-padrÃ£o-fsm-em-pyloto_lab)
3. [Estrutura Proposta para pyloto_corp](#3-estrutura-proposta-para-pyloto_corp)
4. [Uso de LLM â€” 3 Pontos CrÃ­ticos](#4-uso-de-llm--3-pontos-crÃ­ticos)
5. [SeleÃ§Ã£o Inteligente de Tipo de Mensagem](#5-seleÃ§Ã£o-inteligente-de-tipo-de-mensagem)
6. [Exemplos PrÃ¡ticos](#6-exemplos-prÃ¡ticos)
7. [Roadmap de ImplementaÃ§Ã£o](#7-roadmap-de-implementaÃ§Ã£o)

---

## 1. AnÃ¡lise Comparativa

### 1.1 pyloto_lab â€” Estado Atual

**ForÃ§a:** Arquitetura FSM bem definida e modular

```
pyloto_lab/modules/fsm/
â”œâ”€â”€ engine.py                 # Dispatcher puro (sem side effects)
â”œâ”€â”€ pedido/
â”‚   â”œâ”€â”€ states.py            # Enum de estados (DRAFT â†’ COMPLETED)
â”‚   â”œâ”€â”€ events.py            # Enum de eventos
â”‚   â”œâ”€â”€ transitions.py       # Tabela de transiÃ§Ãµes (state + event â†’ next_state)
â”‚   â””â”€â”€ validators.py        # Validadores de campo/contexto
â”œâ”€â”€ subfsm/                  # Sub-mÃ¡quinas (sub-fluxos)
â”‚   â”œâ”€â”€ collecting_data.py
â”‚   â”œâ”€â”€ pricing.py
â”‚   â”œâ”€â”€ payment.py
â”‚   â””â”€â”€ dispatching.py
â””â”€â”€ contracts/               # Schemas Pydantic
    â”œâ”€â”€ context_schema.py
    â””â”€â”€ event_schema.py
```

**CaracterÃ­sticas:**
- âœ… Estados: 11 estados canonicais (DRAFT, COLLECTING_DATA, PRICING, etc.)
- âœ… TransiÃ§Ãµes: Tabela explÃ­cita (state + event â†’ next_state)
- âœ… Validadores: Schema validation antes de transiÃ§Ã£o
- âœ… AÃ§Ãµes: Mapping (event â†’ [actions])
- âœ… Dispatcher puro: Sem side effects, 100% determinÃ­stico

**Fraquezas:**
- âŒ Sem LLM para ajuda contextual
- âŒ Respostas hardcoded por assistente
- âŒ Sem seleÃ§Ã£o automÃ¡tica de tipo de mensagem
- âŒ Sem adaptaÃ§Ã£o dinÃ¢mica a contexto novo

---

### 1.2 pyloto_corp â€” Estado Atual

**ForÃ§a:** Tipos de mensagens completos e testados

```
pyloto_corp/
â”œâ”€â”€ src/pyloto_corp/
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ whatsapp_message_types.py  # 16 tipos (TEXT, VIDEO, etc.)
â”‚   â”‚   â”œâ”€â”€ constants.py
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”œâ”€â”€ application/
â”‚   â”‚   â”œâ”€â”€ message_sender.py          # Envio de mensagens
â”‚   â”‚   â””â”€â”€ webhook_handler.py         # Recebimento
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ orquestrador.py
â”‚   â”‚   â””â”€â”€ prompts/
â”‚   â””â”€â”€ infra/
â”‚       â””â”€â”€ meta_client.py
â”œâ”€â”€ Funcionamento.md                   # Outcomes canÃ´nicos
â””â”€â”€ regras_e_padroes.md               # 7 seÃ§Ãµes de padrÃµes
```

**CaracterÃ­sticas:**
- âœ… Tipos de mensagens: 12 tipos validados (TEXT, IMAGE, VIDEO, INTERACTIVE_BUTTONS, etc.)
- âœ… Outcomes canÃ´nicos: HANDOFF_HUMAN, SELF_SERVE_INFO, ROUTE_EXTERNAL, SCHEDULED_FOLLOWUP
- âœ… Regras de cÃ³digo: Rigorosas e bem documentadas
- âœ… Testes: Abrangentes para cada tipo

**Fraquezas:**
- âŒ Sem FSM explÃ­cito
- âŒ Sem estados canÃ´nicos
- âŒ Sem tabela de transiÃ§Ãµes
- âŒ Sem coordenaÃ§Ã£o entre turnos de conversa
- âŒ Respostas geradas ad-hoc (sem estrutura)

---

### 1.3 Oportunidade: Combinar PadrÃµes

| Aspecto | pyloto_lab | pyloto_corp | Proposta |
|---------|-----------|-----------|----------|
| **FSM ExplÃ­cito** | âœ… Completo | âŒ Ausente | Adaptar states + transitions |
| **Tipos de Mensagem** | âŒ GenÃ©rico | âœ… 12 tipos | Manter + usar inteligentemente |
| **LLM** | âš ï¸ Aux. bÃ¡sico | âš ï¸ Ad-hoc | **Novo: 3 pontos crÃ­ticos** |
| **SeleÃ§Ã£o de Tipo** | âŒ NÃ£o | âŒ NÃ£o | **Novo: DinÃ¢mica via LLM** |

---

## 2. PadrÃ£o FSM em pyloto_lab

### 2.1 Estrutura Core

**engine.py:** Dispatcher puro
```python
def dispatch(
    current_state: PedidoState | str,
    event: PedidoEvent | str,
    payload: dict | None = None,
    context: FSMContext | None = None,
) -> dict[str, Any]:
    """
    Entrada: Estado atual, evento, payload, contexto
    SaÃ­da: {next_state, actions, errors}
    Sem side effects.
    """
```

**pedido/transitions.py:** Tabela de transiÃ§Ãµes
```python
TRANSITIONS = {
    PedidoState.DRAFT: {
        PedidoEvent.START_ORDER_DELIVERY: PedidoState.COLLECTING_DATA,
        PedidoEvent.START_ORDER_SERVICE: PedidoState.COLLECTING_DATA,
    },
    PedidoState.COLLECTING_DATA: {
        PedidoEvent.DATA_COLLECTED: PedidoState.PRICING,
    },
    # ... mais transiÃ§Ãµes
}
```

**pedido/events.py:** CatÃ¡logo de eventos
```python
class PedidoEvent(str, Enum):
    START_ORDER_DELIVERY = "START_ORDER_DELIVERY"
    START_ORDER_SERVICE = "START_ORDER_SERVICE"
    DATA_COLLECTED = "DATA_COLLECTED"
    REQUEST_PRICING = "REQUEST_PRICING"
    CONFIRM_ORDER = "CONFIRM_ORDER"
    PAYMENT_CONFIRMED = "PAYMENT_CONFIRMED"
    # ...
```

### 2.2 Fluxo de DecisÃ£o

```
user_input
  â†“
[webhook handler]
  â†“
[extract intent] â† LLM: "Qual evento disparou?"
  â†“
[load context] â† Redis/Firestore
  â†“
[dispatch(current_state, event, payload, context)]
  â†“
[validate] â† Schema + business rules
  â†“
{next_state, actions, errors}
  â†“
[execute actions] â† Enviar mensagem, etc.
  â†“
[save new_state] â† Redis/Firestore
  â†“
[send response] â† Mensagem ao usuÃ¡rio
```

### 2.3 Vantagens da Abordagem

- âœ… **DeterminÃ­stico:** TransiÃ§Ãµes explÃ­citas, sem "mÃ¡gica"
- âœ… **TestÃ¡vel:** Cada transiÃ§Ã£o pode ser unitariamente testada
- âœ… **AuditÃ¡vel:** Log de eventos = histÃ³rico completo
- âœ… **EscalÃ¡vel:** FÃ¡cil adicionar novos estados/eventos
- âœ… **Modular:** Cada responsabilidade em seu arquivo

---

## 3. Estrutura Proposta para pyloto_corp

### 3.1 Hierarquia de Pastas

```
src/pyloto_corp/
â”œâ”€â”€ domain/
â”‚   â”œâ”€â”€ whatsapp_message_types.py       # [MANTER] 12 tipos validados
â”‚   â”œâ”€â”€ session/                        # [NOVO]
â”‚   â”‚   â”œâ”€â”€ states.py                   # Estados de conversa
â”‚   â”‚   â”œâ”€â”€ events.py                   # Eventos possÃ­veis
â”‚   â”‚   â””â”€â”€ transitions.py              # Tabela de transiÃ§Ãµes
â”‚   â”œâ”€â”€ constants.py
â”‚   â”œâ”€â”€ errors.py
â”‚   â””â”€â”€ models.py
â”‚
â”œâ”€â”€ application/
â”‚   â”œâ”€â”€ fsm_engine.py                   # [NOVO] Dispatcher (similar engine.py)
â”‚   â”œâ”€â”€ message_sender.py               # [MODIFICAR] Integrar tipo de mensagem
â”‚   â””â”€â”€ webhook_handler.py              # [MODIFICAR] Extrair evento
â”‚
â”œâ”€â”€ ai/                                 # [NOVO] IA para 3 pontos
â”‚   â”œâ”€â”€ orchestrator.py                 # Coordena chamadas de LLM
â”‚   â”œâ”€â”€ assistant_event_detector.py     # Ponto 1: Qual evento?
â”‚   â”œâ”€â”€ assistant_response_generator.py # Ponto 2: Qual resposta?
â”‚   â”œâ”€â”€ assistant_message_type.py       # Ponto 3: Qual tipo de mensagem?
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ prompts.yaml               # Prompts versionados
â”‚   â”‚   â””â”€â”€ assistants.yaml            # Config de assistentes
â”‚   â””â”€â”€ contracts/
â”‚       â”œâ”€â”€ event_detection.py
â”‚       â”œâ”€â”€ response_generation.py
â”‚       â””â”€â”€ message_type_selection.py
â”‚
â””â”€â”€ infra/
    â”œâ”€â”€ meta_client.py
    â””â”€â”€ storage.py                      # [MODIFICAR] Salvar estado
```

### 3.2 Estados de Conversa (Session States)

**domain/session/states.py**

```python
from enum import Enum

class SessionState(str, Enum):
    """Estados de uma sessÃ£o de atendimento inicial."""
    
    # Fase 1: Entrada
    INITIAL = "INITIAL"                    # RecÃ©m-chegou
    AWAITING_INTENT = "AWAITING_INTENT"    # Esperando intenÃ§Ã£o
    
    # Fase 2: Coleta
    TRIAGE = "TRIAGE"                      # Identificando tipo
    COLLECTING_INFO = "COLLECTING_INFO"    # Coletando dados
    
    # Fase 3: Resposta
    GENERATING_RESPONSE = "GENERATING_RESPONSE"
    
    # Fase 4: Encerramento
    HANDOFF_HUMAN = "HANDOFF_HUMAN"        # Terminal
    SELF_SERVE_INFO = "SELF_SERVE_INFO"    # Terminal
    ROUTE_EXTERNAL = "ROUTE_EXTERNAL"      # Terminal
    SCHEDULED_FOLLOWUP = "SCHEDULED_FOLLOWUP"  # Terminal
    
    # ExceÃ§Ãµes
    ERROR = "ERROR"
    TIMEOUT = "TIMEOUT"

TERMINAL_STATES = {
    SessionState.HANDOFF_HUMAN,
    SessionState.SELF_SERVE_INFO,
    SessionState.ROUTE_EXTERNAL,
    SessionState.SCHEDULED_FOLLOWUP,
}
```

### 3.3 Eventos de Conversa

**domain/session/events.py**

```python
from enum import Enum

class SessionEvent(str, Enum):
    """Eventos que disparam transiÃ§Ãµes de estado."""
    
    # IntenÃ§Ã£o
    USER_SENT_TEXT = "USER_SENT_TEXT"
    USER_SELECTED_BUTTON = "USER_SELECTED_BUTTON"
    USER_SELECTED_LIST_ITEM = "USER_SELECTED_LIST_ITEM"
    
    # Resposta
    RESPONSE_GENERATED = "RESPONSE_GENERATED"
    MESSAGE_SENT = "MESSAGE_SENT"
    
    # ConclusÃ£o
    HUMAN_HANDOFF_READY = "HUMAN_HANDOFF_READY"
    SELF_SERVE_COMPLETE = "SELF_SERVE_COMPLETE"
    EXTERNAL_ROUTE_READY = "EXTERNAL_ROUTE_READY"
    FOLLOWUP_SCHEDULED = "FOLLOWUP_SCHEDULED"
    
    # ExceÃ§Ãµes
    CONTEXT_ERROR = "CONTEXT_ERROR"
    SESSION_TIMEOUT = "SESSION_TIMEOUT"
    LLM_FAILURE = "LLM_FAILURE"
```

### 3.4 Tabela de TransiÃ§Ãµes

**domain/session/transitions.py**

```python
from .states import SessionState
from .events import SessionEvent

TRANSITIONS = {
    SessionState.INITIAL: {
        SessionEvent.USER_SENT_TEXT: SessionState.TRIAGE,
    },
    
    SessionState.TRIAGE: {
        SessionEvent.RESPONSE_GENERATED: SessionState.COLLECTING_INFO,
    },
    
    SessionState.COLLECTING_INFO: {
        SessionEvent.USER_SENT_TEXT: SessionState.GENERATING_RESPONSE,
        SessionEvent.USER_SELECTED_BUTTON: SessionState.GENERATING_RESPONSE,
        SessionEvent.USER_SELECTED_LIST_ITEM: SessionState.GENERATING_RESPONSE,
    },
    
    SessionState.GENERATING_RESPONSE: {
        SessionEvent.MESSAGE_SENT: SessionState.COLLECTING_INFO,
        SessionEvent.HUMAN_HANDOFF_READY: SessionState.HANDOFF_HUMAN,
        SessionEvent.SELF_SERVE_COMPLETE: SessionState.SELF_SERVE_INFO,
        SessionEvent.EXTERNAL_ROUTE_READY: SessionState.ROUTE_EXTERNAL,
        SessionEvent.FOLLOWUP_SCHEDULED: SessionState.SCHEDULED_FOLLOWUP,
    },
    
    # Terminal states nÃ£o tÃªm transiÃ§Ãµes
}

# AÃ§Ãµes por evento
ACTION_BY_EVENT = {
    SessionEvent.USER_SENT_TEXT: ["DETECT_EVENT", "CHECK_CONTEXT"],
    SessionEvent.RESPONSE_GENERATED: ["SEND_MESSAGE"],
    SessionEvent.MESSAGE_SENT: ["SAVE_STATE"],
    SessionEvent.HUMAN_HANDOFF_READY: ["NOTIFY_HUMAN", "SAVE_STATE"],
}
```

---

## 4. Uso de LLM â€” 3 Pontos CrÃ­ticos

### 4.1 Ponto 1: DetecÃ§Ã£o de Evento (Event Detection)

**Objetivo:** Dado o input do usuÃ¡rio, qual evento disparou?

**Entrada:**
- Mensagem de texto (ou tipo de interaÃ§Ã£o)
- Contexto anterior (histÃ³rico, estado atual)
- IntenÃ§Ã£o conhecida (se houver)

**SaÃ­da:**
```json
{
  "event": "USER_SENT_TEXT",
  "detected_intent": "solicitar_delivery",
  "confidence": 0.95,
  "requires_followup": false
}
```

**Prompt Versionado:**
```yaml
# ai/config/prompts.yaml
event_detection:
  v1:
    system: |
      VocÃª Ã© um detector de intenÃ§Ã£o em conversas de atendimento.
      Dado um input de usuÃ¡rio, identifique qual EVENTO foi disparado.
      
      Eventos vÃ¡lidos: {EVENTS}
      Contexto anterior: {CONTEXT}
      
      Responda em JSON com: {event, detected_intent, confidence}
    
    model: "gpt-4-turbo"
    temperature: 0.3
    max_tokens: 200
```

**ImplementaÃ§Ã£o:**
```python
# ai/assistant_event_detector.py

from typing import Any
from pydantic import BaseModel

class EventDetectionResult(BaseModel):
    event: str
    detected_intent: str
    confidence: float
    requires_followup: bool

async def detect_event(
    user_input: str,
    context: dict[str, Any],
    llm_client: Any,  # OpenAI, Anthropic, etc.
) -> EventDetectionResult:
    """
    Chamar LLM para detectar evento.
    
    Fluxo:
    1. Carregar prompt de config
    2. Substituir variÃ¡veis (context, eventos vÃ¡lidos)
    3. Chamar LLM
    4. Parse resposta em EventDetectionResult
    5. Validar confianÃ§a (se < threshold, escalable error)
    """
    prompt = get_prompt("event_detection", version="v1")
    prompt = prompt.format(
        EVENTS=",".join([e.value for e in SessionEvent]),
        CONTEXT=json.dumps(context),
        USER_INPUT=user_input,
    )
    
    response = await llm_client.create_message(
        model="gpt-4-turbo",
        system="...",
        user_message=prompt,
        temperature=0.3,
    )
    
    result = EventDetectionResult.model_validate_json(response.content)
    
    if result.confidence < 0.7:
        logger.warning(f"Low confidence event detection: {result}")
    
    return result
```

---

### 4.2 Ponto 2: GeraÃ§Ã£o de Resposta (Response Generation)

**Objetivo:** Dado o evento e contexto, qual deve ser a resposta?

**Entrada:**
- Evento detectado
- Contexto (histÃ³rico, estado da conversa)
- IntenÃ§Ã£o do usuÃ¡rio
- Perfil do usuÃ¡rio (se disponÃ­vel)

**SaÃ­da:**
```json
{
  "text_content": "Qual Ã© o tipo de serviÃ§o que vocÃª procura?",
  "suggested_next_state": "COLLECTING_INFO",
  "requires_human_review": false
}
```

**Prompt Versionado:**
```yaml
response_generation:
  v1:
    system: |
      VocÃª Ã© um assistente de atendimento Pyloto.
      Gere uma resposta natural, profissional e concisa.
      
      CONTEXTO: {CONTEXT}
      EVENTO: {EVENT}
      INTENÃ‡ÃƒO DETECTADA: {INTENT}
      
      Responda com JSON: {text_content, suggested_next_state, requires_human_review}
    
    model: "gpt-4-turbo"
    temperature: 0.7
    max_tokens: 500
```

**ImplementaÃ§Ã£o:**
```python
# ai/assistant_response_generator.py

from typing import Any
from pydantic import BaseModel

class ResponseGenerationResult(BaseModel):
    text_content: str
    suggested_next_state: str
    requires_human_review: bool
    confidence: float

async def generate_response(
    event: str,
    context: dict[str, Any],
    user_input: str,
    llm_client: Any,
) -> ResponseGenerationResult:
    """
    Chamar LLM para gerar resposta contextualizada.
    """
    prompt = get_prompt("response_generation", version="v1")
    prompt = prompt.format(
        CONTEXT=json.dumps(context),
        EVENT=event,
        INTENT=context.get("detected_intent", "unknown"),
        USER_INPUT=user_input,
    )
    
    response = await llm_client.create_message(
        model="gpt-4-turbo",
        system="...",
        user_message=prompt,
        temperature=0.7,
    )
    
    result = ResponseGenerationResult.model_validate_json(response.content)
    
    if result.requires_human_review:
        logger.info(f"Response flagged for human review: {result}")
    
    return result
```

---

### 4.3 Ponto 3: SeleÃ§Ã£o de Tipo de Mensagem (Message Type Selection)

**â­ NOVO E CRUCIAL: InteligÃªncia DinÃ¢mica**

**Objetivo:** Dado o contexto e resposta, qual tipo de mensagem usar?

**Exemplos:**
- Pergunta Sim/NÃ£o â†’ `InteractiveButtonMessage` (botÃµes "Sim" / "NÃ£o")
- Pergunta com mÃºltiplas opÃ§Ãµes â†’ `InteractiveListMessage` (lista com seÃ§Ãµes)
- InformaÃ§Ã£o simples â†’ `TextMessage`
- Link importante â†’ `InteractiveCTAURLMessage`
- EndereÃ§o para delivery â†’ `LocationMessage`
- Contato para suporte â†’ `ContactMessage`

**Entrada:**
```json
{
  "text_content": "Qual Ã© o tipo de serviÃ§o?",
  "response_type": "question_with_options",
  "options": ["Delivery", "ServiÃ§o no Local", "Consultoria"],
  "context": {
    "user_profile": "new_client",
    "conversation_turn": 2
  }
}
```

**SaÃ­da:**
```json
{
  "message_type": "InteractiveListMessage",
  "parameters": {
    "body": "Qual Ã© o tipo de serviÃ§o que vocÃª procura?",
    "button": "Ver OpÃ§Ãµes",
    "sections": [
      {
        "title": "ServiÃ§os",
        "rows": [
          {"id": "delivery", "title": "Delivery", "description": "Entrega de produtos"},
          {"id": "service", "title": "ServiÃ§o no Local", "description": "Atendimento presencial"},
          {"id": "consulting", "title": "Consultoria", "description": "OrientaÃ§Ã£o especializada"}
        ]
      }
    ],
    "footer": "Escolha uma opÃ§Ã£o para continuar"
  },
  "confidence": 0.92,
  "rationale": "Pergunta com 3+ opÃ§Ãµes: InteractiveListMessage melhora UX"
}
```

**Prompt Versionado:**
```yaml
message_type_selection:
  v1:
    system: |
      VocÃª Ã© um seletor de tipos de mensagem WhatsApp.
      Dado um contexto e uma resposta, escolha o MELHOR tipo de mensagem.
      
      Tipos disponÃ­veis:
      - TextMessage: Texto simples
      - ImageMessage: Imagem
      - VideoMessage: VÃ­deo (H.264 + AAC)
      - InteractiveButtonMessage: BotÃµes (1-3)
      - InteractiveListMessage: Lista com seÃ§Ãµes (1-10 seÃ§Ãµes)
      - InteractiveCTAURLMessage: URL com botÃ£o
      - LocationMessage: LocalizaÃ§Ã£o geogrÃ¡fica
      - ContactMessage: CartÃ£o de contato
      - TemplateMessage: Template prÃ©-aprovado
      - ReactionMessage: Emoji de reaÃ§Ã£o
      
      CONTEXTO: {CONTEXT}
      RESPOSTA: {RESPONSE}
      OPÃ‡Ã•ES (se houver): {OPTIONS}
      
      Responda com JSON:
      {message_type, parameters, confidence, rationale}
    
    model: "gpt-4-turbo"
    temperature: 0.5
    max_tokens: 800
```

**ImplementaÃ§Ã£o:**
```python
# ai/assistant_message_type.py

from typing import Any
from pydantic import BaseModel
from domain.whatsapp_message_types import (
    TextMessage,
    InteractiveButtonMessage,
    InteractiveListMessage,
    # ... outros tipos
)

class MessageTypeSelectionResult(BaseModel):
    message_type: str  # Nome da classe
    parameters: dict[str, Any]  # ParÃ¢metros para instanciar
    confidence: float
    rationale: str

async def select_message_type(
    response_content: str,
    context: dict[str, Any],
    options: list[str] | None = None,
    llm_client: Any = None,
) -> MessageTypeSelectionResult:
    """
    Chamar LLM para selecionar melhor tipo de mensagem.
    
    Fluxo:
    1. Carregar prompt de config
    2. Analisar response_content (tipo de pergunta?)
    3. Chamar LLM com contexto
    4. Parse em MessageTypeSelectionResult
    5. Validar contra schema do tipo (via Pydantic)
    6. Retornar instÃ¢ncia pronta para enviar
    """
    prompt = get_prompt("message_type_selection", version="v1")
    prompt = prompt.format(
        CONTEXT=json.dumps(context),
        RESPONSE=response_content,
        OPTIONS=json.dumps(options or []),
    )
    
    response = await llm_client.create_message(
        model="gpt-4-turbo",
        system="...",
        user_message=prompt,
        temperature=0.5,
    )
    
    result = MessageTypeSelectionResult.model_validate_json(response.content)
    
    # Validar que o tipo existe
    if result.message_type not in get_available_message_types():
        raise ValueError(f"Unknown message type: {result.message_type}")
    
    # Instanciar e validar parÃ¢metros
    message_class = get_message_class(result.message_type)
    message_instance = message_class(**result.parameters)
    
    logger.info(
        f"Selected {result.message_type} with confidence {result.confidence}",
        extra={"rationale": result.rationale}
    )
    
    return result, message_instance
```

---

## 5. SeleÃ§Ã£o Inteligente de Tipo de Mensagem

### 5.1 Matriz de DecisÃ£o (HeurÃ­stica + LLM)

```
Tipo de Resposta          | Tipo de Mensagem         | ValidaÃ§Ã£o
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Sim/NÃ£o                   | InteractiveButtonMessage | 2 botÃµes exatos
2-3 opÃ§Ãµes                | InteractiveButtonMessage | max_items=3
4+ opÃ§Ãµes                 | InteractiveListMessage   | max_items=10
Pergunta aberta           | TextMessage              | apenas texto
URL importante            | InteractiveCTAURLMessage | URL validada
EndereÃ§o/Mapa             | LocationMessage          | lat/lon corretos
Contato do suporte        | ContactMessage           | vCard vÃ¡lido
InformaÃ§Ã£o com imagem     | ImageMessage + TextMsg   | imagem acessÃ­vel
VÃ­deo tutorial            | VideoMessage             | H.264 + AAC
Template (newsletter)     | TemplateMessage          | template aprovado
```

### 5.2 Exemplos PrÃ¡ticos

#### Exemplo 1: Pergunta Sim/NÃ£o

**Contexto:**
```json
{
  "user_intent": "solicitar_delivery",
  "conversation_turn": 2,
  "next_question": "VocÃª Ã© cliente Pyloto?",
  "expected_answer_type": "boolean"
}
```

**LLM Decision Process:**
```
1. Detectar: resposta_type = "yes_no_question"
2. Gerar: "JÃ¡ Ã© cliente Pyloto ou Ã© sua primeira vez?"
3. Selecionar tipo:
   - Input: {"type": "yes_no", "text": "JÃ¡ Ã© cliente Pyloto..."}
   - LLM: "Esta Ã© uma pergunta sim/nÃ£o â†’ InteractiveButtonMessage"
   - Output:
     {
       "message_type": "InteractiveButtonMessage",
       "parameters": {
         "body": "JÃ¡ Ã© cliente Pyloto ou Ã© sua primeira vez?",
         "buttons": [
           {"id": "btn_yes", "title": "Sou cliente"},
           {"id": "btn_no", "title": "Primeira vez"}
         ],
         "footer": "Escolha uma opÃ§Ã£o"
       }
     }
```

**Resultado Esperado:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JÃ¡ Ã© cliente Pyloto ou Ã© sua        â”‚
â”‚ primeira vez?                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Sou cliente]  [Primeira vez]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Escolha uma opÃ§Ã£o                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Exemplo 2: Pergunta com MÃºltiplas OpÃ§Ãµes

**Contexto:**
```json
{
  "user_intent": "solicitar_delivery",
  "conversation_turn": 3,
  "next_question": "Qual tipo de serviÃ§o?",
  "options": ["Delivery de alimentos", "Delivery de compras", "ServiÃ§o de limpeza"],
  "expected_answer_type": "single_choice_from_list"
}
```

**LLM Decision Process:**
```
1. Detectar: resposta_type = "multiple_choice"
2. Gerar: "Qual tipo de serviÃ§o vocÃª procura?"
3. Selecionar tipo:
   - Input: {
       "type": "multiple_choice",
       "text": "Qual tipo de serviÃ§o...",
       "options": [...3 opÃ§Ãµes]
     }
   - LLM: "Mais de 3 opÃ§Ãµes â†’ InteractiveListMessage com seÃ§Ãµes"
   - Output:
     {
       "message_type": "InteractiveListMessage",
       "parameters": {
         "body": "Qual tipo de serviÃ§o vocÃª procura?",
         "button": "Ver OpÃ§Ãµes",
         "sections": [
           {
             "title": "Categorias",
             "rows": [
               {
                 "id": "food_delivery",
                 "title": "Alimentos",
                 "description": "Entrega de restaurantes"
               },
               {
                 "id": "shopping_delivery",
                 "title": "Compras",
                 "description": "Entrega de lojas"
               },
               {
                 "id": "cleaning_service",
                 "title": "Limpeza",
                 "description": "ServiÃ§o de limpeza"
               }
             ]
           }
         ]
       }
     }
```

**Resultado Esperado:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Qual tipo de serviÃ§o    â”‚
â”‚ vocÃª procura?           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Ver OpÃ§Ãµes â–¼]          â”‚
â”‚                         â”‚
â”‚ CATEGORIAS              â”‚
â”‚ â€¢ Alimentos             â”‚
â”‚   Entrega de           â”‚
â”‚   restaurantes         â”‚
â”‚ â€¢ Compras               â”‚
â”‚   Entrega de lojas     â”‚
â”‚ â€¢ Limpeza               â”‚
â”‚   ServiÃ§o de limpeza   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Pyloto - Menu          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Exemplo 3: URL com CTA

**Contexto:**
```json
{
  "message_type": "offer_link",
  "content": "Veja nosso catÃ¡logo completo",
  "url": "https://example.com/catalog",
  "user_profile": "new_client"
}
```

**LLM Decision:**
```
- Input: {"type": "url_with_cta", "text": "Veja nosso catÃ¡logo..."}
- LLM: "Link importante com call-to-action â†’ InteractiveCTAURLMessage"
- Output:
  {
    "message_type": "InteractiveCTAURLMessage",
    "parameters": {
      "body": "ConheÃ§a todos os nossos serviÃ§os!",
      "cta_url": "https://example.com/catalog",
      "cta_display_text": "Ver CatÃ¡logo",
      "footer": "Clique para explorar"
    }
  }
```

---

## 6. Exemplos PrÃ¡ticos

### 6.1 Fluxo Completo: Do Input ao Output

**Turno 1: UsuÃ¡rio entra na conversa**

```
INPUT:
  user_message: "OlÃ¡, preciso fazer um pedido"
  
STEP 1 (Event Detection):
  LLM: "O que Ã© evento?"
  OUTPUT: {event: "USER_SENT_TEXT", intent: "start_order"}
  
STEP 2 (FSM Dispatch):
  current_state: INITIAL
  event: USER_SENT_TEXT
  â†’ next_state: TRIAGE
  â†’ actions: [DETECT_EVENT, CHECK_CONTEXT]
  
STEP 3 (Response Generation):
  LLM: "O que responder?"
  OUTPUT: {text_content: "Bem-vindo! Para melhor atendÃª-lo, qual tipo de serviÃ§o vocÃª procura?"}
  
STEP 4 (Message Type Selection):
  LLM: "Qual tipo de mensagem?"
  INPUT: {
    response: "Bem-vindo! Para melhor...",
    options: ["Delivery", "ServiÃ§o", "Consultoria"],
    context: {turn: 1, is_first_contact: true}
  }
  OUTPUT: {
    message_type: "InteractiveListMessage",
    parameters: {...}
  }
  
STEP 5 (Send):
  send_whatsapp_message(message_type_instance)
  
STEP 6 (Save State):
  save_session_context({
    state: COLLECTING_INFO,
    last_sent_message_type: InteractiveListMessage,
    turn: 1
  })

OUTPUT (To User):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Bem-vindo Ã  Pyloto!     â”‚
  â”‚                         â”‚
  â”‚ Qual tipo de serviÃ§o    â”‚
  â”‚ vocÃª procura?           â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ [Ver OpÃ§Ãµes â–¼]          â”‚
  â”‚                         â”‚
  â”‚ SERVIÃ‡OS                â”‚
  â”‚ â€¢ Delivery              â”‚
  â”‚ â€¢ ServiÃ§o no Local      â”‚
  â”‚ â€¢ Consultoria           â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ Pyloto - Bem-vindo      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 6.2 Arquivo de ConfiguraÃ§Ã£o Versionado

**ai/config/prompts.yaml**

```yaml
# Prompts versionados por responsabilidade

event_detection:
  v1:
    system: |
      VocÃª Ã© detector de intenÃ§Ã£o em conversas de atendimento Pyloto.
      Seu trabalho Ã© identificar qual EVENTO foi disparado pelo usuÃ¡rio.
      
      Eventos vÃ¡lidos: {EVENTS}
      
      HistÃ³rico da conversa:
      {HISTORY}
      
      Input do usuÃ¡rio:
      {USER_INPUT}
      
      Responda SEMPRE em JSON com este formato:
      {{
        "event": "<EventName>",
        "detected_intent": "<intent_description>",
        "confidence": <0.0-1.0>,
        "requires_followup": <true|false>
      }}
    
    model: "gpt-4-turbo"
    temperature: 0.3
    max_tokens: 200
    
  v2:
    # VersÃ£o melhorada com mais contexto
    system: |
      [versÃ£o melhorada do v1]
    model: "gpt-4"
    temperature: 0.2

response_generation:
  v1:
    system: |
      VocÃª Ã© um assistente de atendimento Pyloto.
      Seu objetivo Ã© gerar uma resposta natural, profissional e concisa
      que avance a conversa de forma eficiente.
      
      REGRAS:
      1. MÃ¡ximo 2-3 frases
      2. Tom profissional mas amigÃ¡vel
      3. Sempre forneÃ§a prÃ³ximo passo claro
      4. Sem jargÃ£o tÃ©cnico
      
      Contexto atual:
      {CONTEXT}
      
      Evento detectado:
      {EVENT}
      
      Responda em JSON:
      {{
        "text_content": "<resposta_para_enviar>",
        "suggested_next_state": "<prÃ³ximo_estado>",
        "requires_human_review": <true|false>
      }}
    
    model: "gpt-4-turbo"
    temperature: 0.7
    max_tokens: 500

message_type_selection:
  v1:
    system: |
      VocÃª Ã© um seletor de tipos de mensagem WhatsApp.
      
      Tipos disponÃ­veis:
      - TextMessage
      - ImageMessage
      - VideoMessage
      - InteractiveButtonMessage (1-3 botÃµes)
      - InteractiveListMessage (1-10 seÃ§Ãµes)
      - InteractiveCTAURLMessage (URL + botÃ£o)
      - LocationMessage
      - ContactMessage
      - TemplateMessage
      - ReactionMessage
      
      Escolha o MELHOR tipo para esta situaÃ§Ã£o.
      
      Resposta a enviar:
      {RESPONSE}
      
      Contexto:
      {CONTEXT}
      
      Responda em JSON:
      {{
        "message_type": "<TypeName>",
        "parameters": {{<parÃ¢metros_especÃ­ficos>}},
        "confidence": <0.0-1.0>,
        "rationale": "<explicaÃ§Ã£o>"
      }}
    
    model: "gpt-4-turbo"
    temperature: 0.5
    max_tokens: 800
```

---

## 7. Roadmap de ImplementaÃ§Ã£o

### Fase 1: FundaÃ§Ã£o FSM (Semana 1-2)

**Tarefas:**
- [ ] Criar `domain/session/states.py` com 10+ estados
- [ ] Criar `domain/session/events.py` com 10+ eventos
- [ ] Criar `domain/session/transitions.py` com tabela completa
- [ ] Criar `application/fsm_engine.py` (dispatcher puro, similar a `engine.py` de pyloto_lab)
- [ ] Testes unitÃ¡rios para cada transiÃ§Ã£o
- [ ] DocumentaÃ§Ã£o no README

**EntregÃ¡veis:**
- FSM funcionando end-to-end
- Testes com 95%+ cobertura
- Arquivo de estados congelado em `regras_e_padroes.md`

---

### Fase 2: LLM â€” Event Detection (Semana 2-3)

**Tarefas:**
- [ ] Criar `ai/assistant_event_detector.py`
- [ ] Criar contrato `ai/contracts/event_detection.py`
- [ ] Versionar prompt em `ai/config/prompts.yaml`
- [ ] Testar com casos reais (usuÃ¡rios de teste)
- [ ] Medir confianÃ§a (threshold >= 0.7)
- [ ] Logging estruturado com correlationId

**EntregÃ¡veis:**
- Event detector funcionando
- Teste com 20+ tipos de input
- MÃ©trica de confianÃ§a rastreada

---

### Fase 3: LLM â€” Response Generation (Semana 3-4)

**Tarefas:**
- [ ] Criar `ai/assistant_response_generator.py`
- [ ] Criar contrato `ai/contracts/response_generation.py`
- [ ] Versionar prompt v1
- [ ] Integrar com contexto de conversa
- [ ] Testar com contextos variados
- [ ] Implementar flagging de "requires_human_review"

**EntregÃ¡veis:**
- Response generator funcionando
- Teste com 30+ scenarios
- Human review metrics

---

### Fase 4: LLM â€” Message Type Selection â­ (Semana 4-5)

**Tarefas:**
- [ ] Criar `ai/assistant_message_type.py`
- [ ] Criar contrato `ai/contracts/message_type_selection.py`
- [ ] Versionar prompt v1
- [ ] Mapear resposta_type â†’ message_type (heurÃ­sticas)
- [ ] Testar seleÃ§Ã£o com 50+ scenarios
- [ ] Validar parÃ¢metros de mensagem (Pydantic)
- [ ] Implementar fallback (se LLM falhar, usar heurÃ­stica)

**EntregÃ¡veis:**
- Message type selector funcionando
- Teste com todos os 12 tipos
- Confidence metrics

---

### Fase 5: IntegraÃ§Ã£o Completa (Semana 5-6)

**Tarefas:**
- [ ] Criar `ai/orchestrator.py` que coordena 3 pontos de LLM
- [ ] Atualizar `application/webhook_handler.py` para usar FSM + LLM
- [ ] Atualizar `application/message_sender.py` para instanciar tipo correto
- [ ] IntegraÃ§Ã£o com Redis/Firestore para persisting estado
- [ ] E2E testing com fluxos reais
- [ ] Load testing (capacidade de requisiÃ§Ãµes/s)

**EntregÃ¡veis:**
- Sistema end-to-end funcionando
- 10+ fluxos testados
- DocumentaÃ§Ã£o de uso

---

### Fase 6: OtimizaÃ§Ã£o + Monitoramento (Semana 6-7)

**Tarefas:**
- [ ] AnÃ¡lise de logs (confusÃ£o em eventos, fallbacks)
- [ ] IteraÃ§Ã£o v2 de prompts (baseado em feedback)
- [ ] Caching de decisÃµes (Redis)
- [ ] MÃ©tricas Prometheus (latÃªncia, erros, confianÃ§a)
- [ ] Dashboard de monitoramento
- [ ] A/B test de prompts

**EntregÃ¡veis:**
- Sistema otimizado
- Dashboard de health
- Runbook de troubleshooting

---

## 8. Estrutura de Arquivos Resumida

```
src/pyloto_corp/
â”œâ”€â”€ domain/session/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ states.py           # 10+ estados canÃ´nicos
â”‚   â”œâ”€â”€ events.py           # 10+ eventos possÃ­veis
â”‚   â””â”€â”€ transitions.py      # Tabela FSM
â”‚
â”œâ”€â”€ application/
â”‚   â”œâ”€â”€ fsm_engine.py       # Dispatcher puro (novo)
â”‚   â”œâ”€â”€ message_sender.py   # Modificado: integra tipo
â”‚   â””â”€â”€ webhook_handler.py  # Modificado: extrai evento
â”‚
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py                    # Orquestra 3 LLMs
â”‚   â”œâ”€â”€ assistant_event_detector.py        # Ponto 1
â”‚   â”œâ”€â”€ assistant_response_generator.py    # Ponto 2
â”‚   â”œâ”€â”€ assistant_message_type.py          # Ponto 3 â­
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ prompts.yaml                  # Versionado
â”‚   â””â”€â”€ contracts/
â”‚       â”œâ”€â”€ event_detection.py
â”‚       â”œâ”€â”€ response_generation.py
â”‚       â””â”€â”€ message_type_selection.py
â”‚
â””â”€â”€ infra/
    â”œâ”€â”€ storage.py          # Modificado: salva estado
    â””â”€â”€ meta_client.py
```

---

## 9. ValidaÃ§Ã£o e Testes

### 9.1 Testes UnitÃ¡rios (por camada)

**FSM:**
```python
def test_state_transition_from_initial_to_triage():
    result = dispatch(
        current_state=SessionState.INITIAL,
        event=SessionEvent.USER_SENT_TEXT,
        payload={"user_input": "OlÃ¡"}
    )
    assert result["next_state"] == SessionState.TRIAGE
    assert "DETECT_EVENT" in result["actions"]
```

**Event Detection:**
```python
async def test_event_detection_yes_no_question():
    result = await detect_event(
        user_input="Sim, quero fazer um pedido",
        context={},
        llm_client=mock_llm
    )
    assert result.event == "USER_SENT_TEXT"
    assert result.confidence >= 0.8
```

**Message Type Selection:**
```python
async def test_message_type_for_boolean_question():
    result, message = await select_message_type(
        response_content="VocÃª Ã© cliente Pyloto?",
        context={"question_type": "boolean"},
        llm_client=mock_llm
    )
    assert result.message_type == "InteractiveButtonMessage"
    assert len(message.buttons) == 2
```

### 9.2 Testes E2E (fluxos reais)

```python
async def test_complete_flow_new_client_delivery():
    """Fluxo real: cliente novo solicita delivery."""
    
    # 1. Cliente entra
    input_1 = "OlÃ¡, preciso fazer um pedido"
    result_1 = await run_session_turn(input_1, session_id="new_123")
    assert "InteractiveListMessage" in str(result_1.message)
    
    # 2. Cliente seleciona Delivery
    input_2 = "Delivery"  # Clique em botÃ£o
    result_2 = await run_session_turn(input_2, session_id="new_123")
    assert result_2.state == SessionState.COLLECTING_INFO
    
    # 3. Cliente fornece endereÃ§o
    input_3 = "Rua X, nÃºmero 123"
    result_3 = await run_session_turn(input_3, session_id="new_123")
    assert result_3.message_type in ["TextMessage", "LocationMessage"]
    
    # 4. Conversa encerra
    # ...
    assert result_n.state in TERMINAL_STATES
```

---

## 10. ConclusÃ£o

### Por que esse design?

1. **FSM explÃ­cito:** Estados claro, sem "mÃ¡gica" de fluxo
2. **LLM em 3 pontos:** DetecÃ§Ã£o, GeraÃ§Ã£o, SeleÃ§Ã£o (responsabilidades isoladas)
3. **SeleÃ§Ã£o dinÃ¢mica de tipo:** Adapta UX ao contexto (Sim/NÃ£o â†’ BotÃµes, MÃºltipla escolha â†’ Lista)
4. **Prompts versionados:** FÃ¡cil iterar sem quebrar produÃ§Ã£o
5. **DeterminÃ­stico + Inteligente:** Combina o melhor dos dois mundos

### PrÃ³ximos Passos Recomendados

1. **Validar design:** Code review com arquitetura do banco
2. **Prototipar Fase 1:** Ter FSM funcional em 1 semana
3. **Implementar iterativamente:** Fases 2-4 em paralelo, Fase 5 apÃ³s integraÃ§Ã£o
4. **Monitorar:** Dashboard de confianÃ§a e erros desde dia 1

---

**Documento Preparado Por:** GitHub Copilot (Executor Mode)  
**Data:** 26 de janeiro de 2025  
**Status:** ğŸ“‹ Design Completo â€” Pronto para ImplementaÃ§Ã£o  
**PrÃ³xima RevisÃ£o:** ApÃ³s Prototype (Fase 1)

